dist: trusty

language: scala
sudo: false
cache:
  directories:
    - $HOME/.ivy2
    - $HOME/spark
    - $HOME/.cache/pip
    - $HOME/.pip-cache
    - $HOME/.sbt/launchers
    - $HOME/perl5
scala:
   - 2.11.6
jdk:
  - oraclejdk8
r:
  - release
addons:
  apt:
    sources:
      - ubuntu-toolchain-r-test
      - ppa:marutter/rdev
    packages:
      - gfortran
      - gcc
      - binutils
      - python-pip
      - python-pandas
      - python-numpy
      - gfortran
      - cmake
      - perl
      - cpanminus
      - r-base
      - libcurl4-gnutls-dev
      - libxml2-dev
      - libssl-dev
      - r-base-dev
      - axel
r_packages:
  - Imap
before_install:
  - # Setup Python
  - pip install --user codecov unittest2 nose pep8 pylint
  - # Setup perl
  - cpanm --force --local-lib $HOME/perl5  --quite --notest Pithub || cat ~/.cpanm/build.log
  - cd ./src/main/perl; cpanm --local-lib $HOME/perl5 --force --quiet --installdeps --notest .; cd ../../../
  - PATH="$HOME/perl5/bin${PATH:+:${PATH}}"; export PATH;
  - PERL5LIB=":$HOME/perl5/lib/perl5${PERL5LIB:+:${PERL5LIB}}"; export PERL5LIB;
  - PERL_LOCAL_LIB_ROOT="$HOME/perl5${PERL_LOCAL_LIB_ROOT:+:${PERL_LOCAL_LIB_ROOT}}"; export PERL_LOCAL_LIB_ROOT;
  - PERL_MB_OPT="--install_base \"$HOME/perl5\""; export PERL_MB_OPT;
  - PERL_MM_OPT="INSTALL_BASE=$HOME/perl5"; export PERL_MM_OPT;
script:
  - "export SPARK_CONF_DIR=./log4j/"
  - sbt clean coverage compile package assembly test || (rm -rf ~/.ivy2 ~/.m2 && sbt clean coverage compile package test)
  - "[ -f spark] || mkdir spark && cd spark && axel http://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz && cd .."
  - "tar -xf ./spark/spark-2.2.0-bin-hadoop2.7.tgz"
  - "export SPARK_HOME=`pwd`/spark-2.2.0-bin-hadoop2.7"
  - "export PYTHONPATH=$SPARK_HOME/python:`ls -1 $SPARK_HOME/python/lib/py4j-*-src.zip`:$PYTHONPATH"
  - "PYSPARK_SUBMIT_ARGS='--jars ./target/examples-assembly-0.0.1.jar pyspark-shell' nosetests --with-doctest --doctest-options=+ELLIPSIS --logging-level=INFO --detailed-errors --verbosity=2 --with-coverage --cover-html-dir=./htmlcov"
  - # $SPARK_HOME/bin/spark-submit ./src/main/r/wc.R $SPARK_HOME/README.md
  - # $SPARK_HOME/bin/spark-submit ./src/main/r/dapply.R
after_success:
  - sbt coverageReport || sbt update coverageReport
  - codecov